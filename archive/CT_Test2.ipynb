{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jXlAy_vmgqdp",
        "2Jg-cwYZgvBJ",
        "gFE3o03p5iNW"
      ],
      "gpuType": "T4",
      "mount_file_id": "1RQgOIbpAxv2w9CG1NJAlyKQ7CJV9I6BF",
      "authorship_tag": "ABX9TyPXdDhPkRyq2S+7dkekaKxk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea466e71be334281918a4fea9857f7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_900a3ef1d91e4dafbb71fa7cb27ee7f1",
              "IPY_MODEL_f4d3c920f1184f36812a4f14c92ed094",
              "IPY_MODEL_0cd655d7f3ec42ff8a294a58217f1f1a"
            ],
            "layout": "IPY_MODEL_96a1e1465f8f494893bb5c986a855ca8"
          }
        },
        "900a3ef1d91e4dafbb71fa7cb27ee7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01ee225d5e18480fb9b0e2426161cccc",
            "placeholder": "​",
            "style": "IPY_MODEL_2de06713ea074ef6a1e0ff83e15b1293",
            "value": "Training:   0%"
          }
        },
        "f4d3c920f1184f36812a4f14c92ed094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2431f59327854df2ad8dd05419b40b98",
            "max": 22469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dffccaf27584d77a62e6bd55d091b7f",
            "value": 71
          }
        },
        "0cd655d7f3ec42ff8a294a58217f1f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dc97086529242f5a5dc565935ba2972",
            "placeholder": "​",
            "style": "IPY_MODEL_4ba48dce8c554c86baa141ad8d88614c",
            "value": " 71/22469 [12:28&lt;103:27:37, 16.63s/it, loss=5.87, accuracy=0.00088]"
          }
        },
        "96a1e1465f8f494893bb5c986a855ca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01ee225d5e18480fb9b0e2426161cccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2de06713ea074ef6a1e0ff83e15b1293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2431f59327854df2ad8dd05419b40b98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dffccaf27584d77a62e6bd55d091b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dc97086529242f5a5dc565935ba2972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ba48dce8c554c86baa141ad8d88614c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Astro2350/CT-Train/blob/including-testing/CT_Test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess"
      ],
      "metadata": {
        "id": "jXlAy_vmgqdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# NLTK setup for stopwords and lemmatization\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Function to preprocess text (remove stopwords, lemmatize, clean text)\n",
        "def preprocess_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetical characters\n",
        "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Load raw datasets (they should be in /content/)\n",
        "categories_df = pd.read_csv('list_of_categories.csv')\n",
        "train_df = pd.read_csv('TRAIN.csv')\n",
        "\n",
        "print(\"Preprocessing data...\")\n",
        "\n",
        "# Clean column names\n",
        "train_df.columns = train_df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "categories_df.columns = categories_df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "\n",
        "# Merge datasets to include category information\n",
        "merged_df = train_df.merge(categories_df, left_on='primary_category_id', right_on='id', how='left')\n",
        "\n",
        "# Feature engineering: create combined_text\n",
        "merged_df['name'] = merged_df['name'].fillna('')\n",
        "merged_df['gl_description'] = merged_df['gl_description'].fillna('')\n",
        "merged_df['memo'] = merged_df['memo'].fillna('')\n",
        "merged_df['combined_text'] = merged_df['name'] + ' ' + merged_df['gl_description'] + ' ' + merged_df['memo']\n",
        "\n",
        "# Preprocess text in combined_text column\n",
        "merged_df['combined_text'] = merged_df['combined_text'].apply(preprocess_text)\n",
        "\n",
        "# Encode target variable using LabelEncoder (temporary encoding)\n",
        "label_encoder = LabelEncoder()\n",
        "merged_df['matched_category_id_encoded'] = label_encoder.fit_transform(merged_df['matched_category_id'])\n",
        "print(f\"Number of target classes before filtering: {len(label_encoder.classes_)}\")\n",
        "\n",
        "# Handle categorical features\n",
        "merged_df['hospital_system_id'] = merged_df['hospital_system_id'].astype(str)\n",
        "merged_df['hospital_system_id_encoded'] = LabelEncoder().fit_transform(merged_df['hospital_system_id'])\n",
        "\n",
        "merged_df['department_name'] = merged_df['department_name'].fillna('Unknown')\n",
        "merged_df['department_name_encoded'] = LabelEncoder().fit_transform(merged_df['department_name'])\n",
        "\n",
        "# Handle category hierarchy features (for 6 levels)\n",
        "for i in range(6):\n",
        "    col_name = f'category{i}'\n",
        "    merged_df[col_name] = merged_df[col_name].fillna('Unknown')\n",
        "    merged_df[f'{col_name}_encoded'] = LabelEncoder().fit_transform(merged_df[col_name])\n",
        "\n",
        "# Remove classes with only one sample\n",
        "class_counts = merged_df['matched_category_id_encoded'].value_counts()\n",
        "rare_classes = class_counts[class_counts == 1].index\n",
        "filtered_df = merged_df[~merged_df['matched_category_id_encoded'].isin(rare_classes)].copy()  # Use .copy() to avoid warning\n",
        "\n",
        "# Re-fit the label encoder on the filtered data so that labels become contiguous\n",
        "label_encoder = LabelEncoder()\n",
        "filtered_df['matched_category_id_encoded'] = label_encoder.fit_transform(filtered_df['matched_category_id'])\n",
        "num_classes = filtered_df['matched_category_id_encoded'].nunique()\n",
        "print(f\"Number of classes after filtering: {num_classes}\")\n",
        "\n",
        "# Save the processed data\n",
        "filtered_df.to_csv('/content/processed_train_data.csv', index=False)\n",
        "\n",
        "# Save the re-fitted label encoder for later use in training\n",
        "with open('/content/label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "print(\"Data preprocessing complete and saved to '/content/processed_train_data.csv'!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pt3dDlYgpUB",
        "outputId": "b9771dca-09ff-4976-8fac-67d561eab06c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing data...\n",
            "Number of target classes before filtering: 357\n",
            "Number of classes after filtering: 345\n",
            "Data preprocessing complete and saved to '/content/processed_train_data.csv'!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "2Jg-cwYZgvBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pickle\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "\n",
        "# Load processed data and label encoder\n",
        "train_df = pd.read_csv('/content/processed_train_data.csv')\n",
        "with open('/content/label_encoder.pkl', 'rb') as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "# Determine number of classes from processed data\n",
        "num_classes = train_df['matched_category_id_encoded'].nunique()\n",
        "print(f\"Number of classes from processed data: {num_classes}\")\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "bert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Custom dataset class\n",
        "class TransactionDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.data.iloc[index]\n",
        "        text = row['combined_text']\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "\n",
        "        # Combine categorical features: hospital_system_id_encoded, primary_category_id, department_name_encoded\n",
        "        cat_features = torch.tensor([row['hospital_system_id_encoded'], row['primary_category_id'], row['department_name_encoded']], dtype=torch.long)\n",
        "\n",
        "        # Hierarchical features (6 columns)\n",
        "        hier_features = torch.tensor([row['category0_encoded'], row['category1_encoded'], row['category2_encoded'],\n",
        "                                      row['category3_encoded'], row['category4_encoded'], row['category5_encoded']], dtype=torch.long)\n",
        "\n",
        "        # Amount feature\n",
        "        amount = torch.tensor([row['amount']], dtype=torch.float)\n",
        "\n",
        "        # Target label\n",
        "        target = torch.tensor(row['matched_category_id_encoded'], dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'cat_features': cat_features,\n",
        "            'hier_features': hier_features,\n",
        "            'amount': amount,\n",
        "            'target': target\n",
        "        }\n",
        "\n",
        "# Split the processed data into training and validation sets\n",
        "train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['matched_category_id_encoded'])\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 16\n",
        "train_dataset = TransactionDataset(train_data, tokenizer)\n",
        "val_dataset = TransactionDataset(val_data, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# Define the model\n",
        "class HierarchicalCategoryModel(nn.Module):\n",
        "    def __init__(self, bert_model, num_cat_features=3, num_hier_features=6, num_classes=357):\n",
        "        super(HierarchicalCategoryModel, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.bert_dropout = nn.Dropout(0.1)\n",
        "        self.bert_dim = 768  # DistilBERT hidden size\n",
        "\n",
        "        # Embeddings for categorical features\n",
        "        self.cat_embeddings = nn.ModuleList([nn.Embedding(10000, 32) for _ in range(num_cat_features)])\n",
        "        self.hier_embeddings = nn.ModuleList([nn.Embedding(10000, 32) for _ in range(num_hier_features)])\n",
        "\n",
        "        # Calculate total embedding dimensions\n",
        "        self.cat_emb_dim = 32 * num_cat_features\n",
        "        self.hier_emb_dim = 32 * num_hier_features\n",
        "\n",
        "        # Total input dimension: BERT output + categorical embeddings + hierarchical embeddings + amount\n",
        "        self.total_input_dim = self.bert_dim + self.cat_emb_dim + self.hier_emb_dim + 1\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(self.total_input_dim, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)  # Set to match number of classes\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.batch_norm1 = nn.BatchNorm1d(512)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(256)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, cat_features, hier_features, amount):\n",
        "        # Process BERT output\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        bert_cls = bert_output.last_hidden_state[:, 0, :]\n",
        "        bert_cls = self.bert_dropout(bert_cls)\n",
        "\n",
        "        # Process categorical features\n",
        "        cat_embeddings = [emb(cat_features[:, i]) for i, emb in enumerate(self.cat_embeddings)]\n",
        "        cat_embeddings = torch.cat(cat_embeddings, dim=1)\n",
        "\n",
        "        # Process hierarchical features\n",
        "        hier_embeddings = [emb(hier_features[:, i]) for i, emb in enumerate(self.hier_embeddings)]\n",
        "        hier_embeddings = torch.cat(hier_embeddings, dim=1)\n",
        "\n",
        "        # Concatenate all features\n",
        "        combined = torch.cat([bert_cls, cat_embeddings, hier_embeddings, amount], dim=1)\n",
        "\n",
        "        # Fully connected layers with batch normalization and dropout\n",
        "        x = self.fc1(combined)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        logits = self.fc3(x)\n",
        "        return logits\n",
        "\n",
        "# Initialize device (CPU or CUDA)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Use the number of classes from the processed data\n",
        "print(f\"Setting model num_classes to: {num_classes}\")\n",
        "model = HierarchicalCategoryModel(bert_model, num_classes=num_classes).to(device)\n",
        "\n",
        "# Set up optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "# Compute class weights based on the processed training data (make sure to use the training portion)\n",
        "class_weights = compute_class_weight('balanced',\n",
        "                                     classes=np.unique(train_df['matched_category_id_encoded']),\n",
        "                                     y=train_df['matched_category_id_encoded'])\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "# Mixed Precision Training setup - if CUDA is not available, this will simply be ignored\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, dataloader, optimizer, criterion, device, scaler):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        cat_features = batch['cat_features'].to(device)\n",
        "        hier_features = batch['hier_features'].to(device)\n",
        "        amount = batch['amount'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if device.type == 'cuda':\n",
        "            with autocast(device_type=device.type):\n",
        "                outputs = model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    cat_features=cat_features,\n",
        "                    hier_features=hier_features,\n",
        "                    amount=amount\n",
        "                )\n",
        "                loss = criterion(outputs, targets)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                cat_features=cat_features,\n",
        "                hier_features=hier_features,\n",
        "                amount=amount\n",
        "            )\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        correct_predictions += torch.sum(preds == targets)\n",
        "        total_predictions += targets.shape[0]\n",
        "        epoch_loss += loss.item()\n",
        "        progress_bar.set_postfix({\"loss\": loss.item(), \"accuracy\": (correct_predictions.float() / total_predictions).item()})\n",
        "\n",
        "    return epoch_loss / len(dataloader), correct_predictions.float() / total_predictions\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            cat_features = batch['cat_features'].to(device)\n",
        "            hier_features = batch['hier_features'].to(device)\n",
        "            amount = batch['amount'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                cat_features=cat_features,\n",
        "                hier_features=hier_features,\n",
        "                amount=amount\n",
        "            )\n",
        "            loss = criterion(outputs, targets)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            correct_predictions += torch.sum(preds == targets)\n",
        "            total_predictions += targets.shape[0]\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader), correct_predictions.float() / total_predictions\n",
        "\n",
        "# Training loop with early stopping and checkpoint saving\n",
        "num_epochs = 3\n",
        "best_accuracy = 0\n",
        "patience = 3\n",
        "epochs_no_improve = 0\n",
        "\n",
        "checkpoint_dir = \"/content/drive/MyDrive/checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "log_filepath = \"/content/drive/MyDrive/training_logs.csv\"\n",
        "\n",
        "with open(log_filepath, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Epoch', 'Train Loss', 'Train Accuracy', 'Val Loss', 'Val Accuracy'])\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device, scaler)\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_accuracy:\n",
        "        best_accuracy = val_acc\n",
        "        epochs_no_improve = 0\n",
        "        checkpoint_path = f\"{checkpoint_dir}/best_model.pth\"\n",
        "        # Save checkpoint\n",
        "        def save_checkpoint(model, optimizer, epoch, loss, accuracy, filepath):\n",
        "            checkpoint = {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                'accuracy': accuracy\n",
        "            }\n",
        "            torch.save(checkpoint, filepath)\n",
        "            print(f\"Checkpoint saved to {filepath}\")\n",
        "        save_checkpoint(model, optimizer, epoch + 1, val_loss, val_acc, checkpoint_path)\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
        "            break\n",
        "\n",
        "    with open(log_filepath, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([epoch + 1, train_loss, train_acc.item(), val_loss, val_acc.item()])\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print()\n",
        "\n",
        "print(f\"Best validation accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "best_model_path = f\"{checkpoint_dir}/best_model.pth\"\n",
        "if os.path.exists(best_model_path):\n",
        "    checkpoint = torch.load(best_model_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"Loaded best model from epoch {checkpoint['epoch']} with accuracy {checkpoint['accuracy']:.4f}\")\n",
        "else:\n",
        "    print(\"No saved model found. Using the last trained model.\")\n",
        "\n",
        "category_mapping = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
        "with open(f\"{checkpoint_dir}/category_mapping.json\", 'w') as f:\n",
        "    json.dump(category_mapping, f)\n",
        "print(f\"Category mapping saved to {checkpoint_dir}/category_mapping.json\")\n",
        "\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631,
          "referenced_widgets": [
            "ea466e71be334281918a4fea9857f7b8",
            "900a3ef1d91e4dafbb71fa7cb27ee7f1",
            "f4d3c920f1184f36812a4f14c92ed094",
            "0cd655d7f3ec42ff8a294a58217f1f1a",
            "96a1e1465f8f494893bb5c986a855ca8",
            "01ee225d5e18480fb9b0e2426161cccc",
            "2de06713ea074ef6a1e0ff83e15b1293",
            "2431f59327854df2ad8dd05419b40b98",
            "0dffccaf27584d77a62e6bd55d091b7f",
            "4dc97086529242f5a5dc565935ba2972",
            "4ba48dce8c554c86baa141ad8d88614c"
          ]
        },
        "id": "UmkgF6vXfjJm",
        "outputId": "199db8a7-a962-4818-e252-d3394f86f557"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes from processed data: 345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Setting model num_classes to: 345\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-f524954686d7>:166: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/22469 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea466e71be334281918a4fea9857f7b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f524954686d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-f524954686d7>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, optimizer, criterion, device, scaler)\u001b[0m\n\u001b[1;32m    207\u001b[0m             )\n\u001b[1;32m    208\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "gFE3o03p5iNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import pickle\n",
        "import re\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "\n",
        "# Define the same preprocessing function used during training\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
        "    # Add stopword removal and lemmatization if needed (same as your training code)\n",
        "    return text\n",
        "\n",
        "# Load the sample AP data CSV (ensure it has the same columns as train.csv, minus the target)\n",
        "ap_df = pd.read_csv('sample_ap_data.csv')\n",
        "\n",
        "# Combine text fields and preprocess (ensure consistency with training)\n",
        "ap_df['name'] = ap_df['name'].fillna('')\n",
        "ap_df['gl_description'] = ap_df['gl_description'].fillna('')\n",
        "ap_df['memo'] = ap_df['memo'].fillna('')\n",
        "ap_df['combined_text'] = (ap_df['name'] + ' ' + ap_df['gl_description'] + ' ' + ap_df['memo']).apply(preprocess_text)\n",
        "\n",
        "# Process categorical features (if not already encoded, apply the same transformations as during training)\n",
        "ap_df['hospital_system_id'] = ap_df['hospital_system_id'].astype(str)\n",
        "ap_df['department_name'] = ap_df['department_name'].fillna('Unknown')\n",
        "# For hierarchical features, fill missing values\n",
        "for i in range(6):\n",
        "    col_name = f'category{i}'\n",
        "    ap_df[col_name] = ap_df[col_name].fillna('Unknown')\n",
        "\n",
        "# NOTE: The code below assumes that you have already encoded these features\n",
        "# (e.g., hospital_system_id_encoded, primary_category_id, department_name_encoded,\n",
        "# category0_encoded to category5_encoded, and amount) in the same way as during training.\n",
        "# If not, you will need to transform them using the saved label encoders or mappings.\n",
        "\n",
        "# Load the saved label encoder for the target and model checkpoint\n",
        "with open('/content/label_encoder.pkl', 'rb') as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize tokenizer and pre-trained BERT model\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "bert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Import your HierarchicalCategoryModel definition here (ensure it's available)\n",
        "# For example: from your_model_file import HierarchicalCategoryModel\n",
        "\n",
        "# Create model instance (ensure num_classes matches training setup)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "model = HierarchicalCategoryModel(bert_model, num_classes=num_classes).to(device)\n",
        "\n",
        "# Load the best checkpoint\n",
        "checkpoint_path = \"/content/drive/MyDrive/checkpoints/best_model.pth\"\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "\n",
        "# Loop through the DataFrame rows and predict\n",
        "for idx, row in ap_df.iterrows():\n",
        "    # Tokenize the preprocessed text\n",
        "    text = row['combined_text']\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    # Prepare categorical features: hospital_system_id_encoded, primary_category_id, department_name_encoded\n",
        "    # And hierarchical features: category0_encoded to category5_encoded\n",
        "    # Ensure these columns are available; if not, transform them using the same encoders as training.\n",
        "    cat_features = torch.tensor([[row['hospital_system_id_encoded'], row['primary_category_id'], row['department_name_encoded']]], dtype=torch.long).to(device)\n",
        "    hier_features = torch.tensor([[\n",
        "        row['category0_encoded'], row['category1_encoded'], row['category2_encoded'],\n",
        "        row['category3_encoded'], row['category4_encoded'], row['category5_encoded']\n",
        "    ]], dtype=torch.long).to(device)\n",
        "\n",
        "    # Prepare the amount feature\n",
        "    amount = torch.tensor([[row['amount']]], dtype=torch.float).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            cat_features=cat_features,\n",
        "            hier_features=hier_features,\n",
        "            amount=amount\n",
        "        )\n",
        "\n",
        "    predicted_idx = torch.argmax(outputs, dim=1).item()\n",
        "    predicted_category = label_encoder.inverse_transform([predicted_idx])[0]\n",
        "    predictions.append(predicted_category)\n",
        "\n",
        "# Add predictions to the DataFrame and save to a new CSV\n",
        "ap_df['predicted_category'] = predictions\n",
        "ap_df.to_csv('ap_predictions.csv', index=False)\n",
        "print(\"Predictions saved to ap_predictions.csv\")"
      ],
      "metadata": {
        "id": "PAh5uBN35gyz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
